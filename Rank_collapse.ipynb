{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from XAI import *\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tdc.benchmark_group import admet_group\n",
    "import os\n",
    "from torch import stack, tensor, Generator, cat, float32, nonzero, set_float32_matmul_precision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "set_float32_matmul_precision('high')\n",
    "set_global_seed(42)\n",
    "\n",
    "def get_mode(x, bins):\n",
    "    hist, bins = np.histogram(x, bins)\n",
    "    return bins[np.argmax(hist)]\n",
    "\n",
    "def make_plt(data, label, what = 'mode', confidence = 0.67, bins = 50, ax = None):\n",
    "    \n",
    "    # Calculate mean and standard deviation along dimension 0\n",
    "    if what == 'mean':\n",
    "        mean_values = np.mean(data, axis = 0)\n",
    "    elif what == 'mode':\n",
    "        mean_values = np.apply_along_axis(lambda a: get_mode(a, bins = bins), 0, data)#np.mean(data, axis=0)\n",
    "    else:\n",
    "        raise(ValueError, 'use what = mode or mean')\n",
    "        \n",
    "    percentiles = np.percentile(data, [(1 - confidence) / 2 * 100, (1 + confidence) / 2 * 100], axis=0)\n",
    "    lower_bound = percentiles[0]\n",
    "    upper_bound = percentiles[1]\n",
    "    if ax is None:\n",
    "        plt.plot(mean_values[1:-1], label=label)\n",
    "        plt.fill_between(range(data.shape[1]-2), lower_bound[1:-1], upper_bound[1:-1], alpha=0.1)\n",
    "    else:\n",
    "        ax.plot(mean_values[1:-1], label=label)\n",
    "        ax.fill_between(range(data.shape[1]-2), lower_bound[1:-1], upper_bound[1:-1], alpha=0.1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c04410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group = admet_group(path = '../data_tdc/')\n",
    "names = group.dataset_names\n",
    "data = {}\n",
    "seeds = [1]\n",
    "models = [\n",
    "    'charges_20L_wide_def_2e-5_16p', \n",
    "    'nmr_20L_wide_def_2e-5_16p', \n",
    "    'fukui_n_20L_wide_def_2e-5_16p', \n",
    "    'fukui_e_20L_wide_def_2e-5_16p', \n",
    "    'homo-lumo_20L_wide_def_2e-5_16p', \n",
    "    'qm_all_20L_wide_def_2e-5_16p', \n",
    "    'masking_20L_wide_def_2e-5_16p', \n",
    "    'scratch_20L_wide_def_2e-5_16p'\n",
    "]\n",
    "\n",
    "ranks = {}\n",
    "seed = 1\n",
    "\n",
    "for name in names:\n",
    "    \n",
    "    benchmark = group.get(name) \n",
    "    name = benchmark['name']\n",
    "    train_val, test = benchmark['train_val'], benchmark['test']\n",
    "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
    "    try:\n",
    "        smiles=test['Drug'].sample(100).values.tolist()\n",
    "    except:\n",
    "        smiles=test['Drug'].values.tolist()\n",
    "    \n",
    "    ranks[name] = {}\n",
    "    \n",
    "    for model in tqdm(models):\n",
    "\n",
    "        subname = model.split('_')[0]\n",
    "\n",
    "        if subname == 'fukui':\n",
    "            subname = model.split('_')[0] + '_' + model.split('_')[1]\n",
    "\n",
    "        elif subname == 'qm':\n",
    "            subname = 'all'\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        r = []\n",
    "    \n",
    "        for seed in [1]:\n",
    "\n",
    "            print(name, seed, ':\\n')\n",
    "\n",
    "            ckpts = os.listdir(f'./TDC_checkpoints/{model}/{name}_{seed}/')\n",
    "            ckpt = [c for c in ckpts if c.startswith('epoch')][0]\n",
    "\n",
    "            checkpoint_path = f'./TDC_checkpoints/{model}/{name}_{seed}/{ckpt}'\n",
    "            print(checkpoint_path)\n",
    "            loaded_path_hyper_dict = torch.load(checkpoint_path)['hyper_parameters']\n",
    "\n",
    "            model_ = GT(\n",
    "                checkpoint_path = checkpoint_path,\n",
    "                **loaded_path_hyper_dict\n",
    "            )\n",
    "\n",
    "            model_, w = transfer_weights(checkpoint_path, model_, device = 'cuda')\n",
    "\n",
    "            model_.eval()\n",
    "            model_.freeze()\n",
    "\n",
    "            for n, param in model_.named_parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            predictions = {}\n",
    "\n",
    "            dlt = get_iterator(smiles, is_prepared_as_packed_chython=False)\n",
    "\n",
    "            for batch in tqdm(dlt):\n",
    "                r.append(get_rank_residuals(model_, batch))\n",
    "\n",
    "        ranks[name][subname] = r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4569ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ranks_tol.pkl', 'wb') as f:\n",
    "    pickle.dump(ranks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert(original_dict):\n",
    "    inverted_dict = {}\n",
    "    for k, inner_dict in original_dict.items():\n",
    "        for v, c in inner_dict.items():\n",
    "            if v not in inverted_dict:\n",
    "                inverted_dict[v] = {}\n",
    "            inverted_dict[v][k] = c\n",
    "    return inverted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_dict = invert(ranks)\n",
    "ranks = inverted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9aef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ranks_.pkl', 'rb') as f:\n",
    "    ranks = invert(pickle.load(f))\n",
    "    \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "    \n",
    "def make_plt(data, label, what = 'mode', confidence = 0.67, bins = 50, ax = None):\n",
    "    \n",
    "    if what == 'mean':\n",
    "        mean_values = np.mean(data, axis = 0)\n",
    "    elif what == 'mode':\n",
    "        mean_values = np.apply_along_axis(lambda a: get_mode(a, bins = bins), 0, data)#np.mean(data, axis=0)\n",
    "    else:\n",
    "        raise(ValueError, 'use what = mode or mean')\n",
    "        \n",
    "    percentiles = np.percentile(data, [(1 - confidence) / 2 * 100, (1 + confidence) / 2 * 100], axis=0)\n",
    "    lower_bound = percentiles[0]\n",
    "    upper_bound = percentiles[1]\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.plot(mean_values[1:-1], label=label)\n",
    "        plt.fill_between(range(data.shape[1]-2), lower_bound[1:-1], upper_bound[1:-1], alpha=0.1)\n",
    "    \n",
    "    else:\n",
    "        ax.plot(mean_values[1:-1], label=label)\n",
    "        ax.fill_between(range(data.shape[1]-2), lower_bound[1:-1], upper_bound[1:-1], alpha=0.1)\n",
    "        \n",
    "keys = list(ranks.keys())\n",
    "\n",
    "df = pd.DataFrame(np.array([[],[],[]]).T, columns = ['model', 'value', 'layer'])\n",
    "\n",
    "model_list = []\n",
    "value_list = []\n",
    "layer_list = []\n",
    "\n",
    "chiavi = ['all', 'nmr', 'charges', 'fukui_e', 'fukui_n', 'homo-lumo', 'masking', 'scratch']\n",
    "keys = chiavi\n",
    "\n",
    "subsample_index = random.sample(range(0, 2100), 500)\n",
    "\n",
    "for i, c in enumerate(chiavi):\n",
    "    \n",
    "    if c in chiavi:\n",
    "    \n",
    "        trajs = ranks[keys[i]]\n",
    "        ts = []\n",
    "        for k, v in trajs.items():\n",
    "            ts+=v\n",
    "            \n",
    "        ts = np.array(ts)\n",
    "        \n",
    "        for h in range(0,len(ts)):\n",
    "            for g in range(0, len(ts[0])):\n",
    "                value_list += ts[subsample_index,g].tolist()\n",
    "                model_list += [keys[i]]*len(subsample_index)\n",
    "                layer_list += [g]*len(subsample_index)\n",
    "                \n",
    "        \n",
    "        make_plt(np.array(ts), label = f'{keys[i]}', confidence = .67) \n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'] = model_list\n",
    "df['value'] = value_list\n",
    "df['layer'] = layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f7e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,8))\n",
    "sns.boxplot(data=df, x=\"layer\", y=\"value\", hue=\"model\", whis = (15, 85), fill = False, showfliers = False, gap = 0.2)\n",
    "plt.xticks(np.arange(0,19), np.arange(1,20),fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.xlabel(r'$k^{th}$-layer', fontsize = 24)\n",
    "plt.ylabel(r'$\\rho_L$', fontsize = 24)\n",
    "plt.ylim(0,1.4)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
